#!/usr/bin/env python3
"""
Test script for the new AI-integrated reporting functionality.
"""

import asyncio
import sys
import tempfile
from pathlib import Path

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from assembly.project_generator import ProjectGenerator


async def test_ai_integrated_reporting():
    """Test the AI-integrated reporting system."""
    
    print("🧪 Testing AutoBot Assembly AI-Integrated Reporting System")
    print("=" * 70)
    
    try:
        # Create a test project
        with tempfile.TemporaryDirectory() as temp_dir:
            generator = ProjectGenerator()
            
            # Sample project files with more realistic content
            test_files = {
                'main.py': '''#!/usr/bin/env python3
"""
AI API Liaison - Main Application

A comprehensive AI API management system that provides intelligent routing,
cost optimization, and performance monitoring across multiple AI providers.
Generated by AutoBot Assembly System.
"""

import asyncio
import logging
from typing import Dict, List, Optional
from dataclasses import dataclass

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

from core.provider_manager import ProviderManager
from core.routing_engine import RoutingEngine
from resilience.gracy_client import GracyClient
from selection.dynamic_selector import DynamicSelector
from cost.cost_optimizer import CostOptimizer
from monitoring.metrics_collector import MetricsCollector


@dataclass
class APIRequest:
    """API request structure."""
    prompt: str
    model: Optional[str] = None
    max_tokens: Optional[int] = None
    temperature: Optional[float] = None
    provider_preference: Optional[str] = None


class AIAPILiaison:
    """Main AI API Liaison application."""
    
    def __init__(self):
        self.app = FastAPI(
            title="AI API Liaison",
            description="Intelligent AI API management and routing system",
            version="1.0.0"
        )
        
        # Initialize core components
        self.provider_manager = ProviderManager()
        self.routing_engine = RoutingEngine()
        self.gracy_client = GracyClient()
        self.dynamic_selector = DynamicSelector()
        self.cost_optimizer = CostOptimizer()
        self.metrics_collector = MetricsCollector()
        
        # Setup CORS
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        # Setup routes
        self._setup_routes()
        
        # Setup logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def _setup_routes(self):
        """Setup API routes."""
        
        @self.app.post("/v1/chat/completions")
        async def chat_completions(request: APIRequest):
            """OpenAI-compatible chat completions endpoint."""
            try:
                # Select optimal provider
                provider = await self.dynamic_selector.select_provider(
                    request.prompt, request.provider_preference
                )
                
                # Optimize for cost
                optimized_request = await self.cost_optimizer.optimize_request(
                    request, provider
                )
                
                # Route request through resilience layer
                response = await self.gracy_client.make_request(
                    provider, optimized_request
                )
                
                # Collect metrics
                await self.metrics_collector.record_request(
                    provider, request, response
                )
                
                return response
                
            except Exception as e:
                self.logger.error(f"Request failed: {e}")
                raise HTTPException(status_code=500, detail=str(e))
        
        @self.app.get("/health")
        async def health_check():
            """Health check endpoint."""
            return {"status": "healthy", "version": "1.0.0"}
        
        @self.app.get("/metrics")
        async def get_metrics():
            """Get system metrics."""
            return await self.metrics_collector.get_metrics()
    
    async def start_server(self, host: str = "0.0.0.0", port: int = 8000):
        """Start the API server."""
        self.logger.info(f"Starting AI API Liaison on {host}:{port}")
        
        config = uvicorn.Config(
            self.app,
            host=host,
            port=port,
            log_level="info"
        )
        
        server = uvicorn.Server(config)
        await server.serve()


async def main():
    """Main function."""
    liaison = AIAPILiaison()
    await liaison.start_server()


if __name__ == "__main__":
    asyncio.run(main())
''',
                'core/provider_manager.py': '''"""
Provider Manager

Manages multiple AI providers with health monitoring and failover capabilities.
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum

import aiohttp
from tenacity import retry, stop_after_attempt, wait_exponential


class ProviderStatus(Enum):
    """Provider status enumeration."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    OFFLINE = "offline"


@dataclass
class Provider:
    """AI provider configuration."""
    name: str
    api_key: str
    base_url: str
    models: List[str]
    rate_limit: int
    cost_per_token: float
    status: ProviderStatus = ProviderStatus.HEALTHY
    last_check: Optional[float] = None


class ProviderManager:
    """Manages AI providers with health monitoring."""
    
    def __init__(self):
        self.providers: Dict[str, Provider] = {}
        self.logger = logging.getLogger(__name__)
        self._load_providers()
    
    def _load_providers(self):
        """Load provider configurations."""
        # OpenAI
        self.providers["openai"] = Provider(
            name="openai",
            api_key="",  # Set from environment
            base_url="https://api.openai.com/v1",
            models=["gpt-4", "gpt-3.5-turbo"],
            rate_limit=3000,
            cost_per_token=0.03
        )
        
        # Anthropic
        self.providers["anthropic"] = Provider(
            name="anthropic",
            api_key="",  # Set from environment
            base_url="https://api.anthropic.com/v1",
            models=["claude-3-opus", "claude-3-sonnet"],
            rate_limit=1000,
            cost_per_token=0.015
        )
        
        # Google
        self.providers["google"] = Provider(
            name="google",
            api_key="",  # Set from environment
            base_url="https://generativelanguage.googleapis.com/v1",
            models=["gemini-pro", "gemini-pro-vision"],
            rate_limit=60,
            cost_per_token=0.001
        )
    
    async def get_healthy_providers(self) -> List[Provider]:
        """Get list of healthy providers."""
        healthy = []
        
        for provider in self.providers.values():
            if provider.status == ProviderStatus.HEALTHY:
                healthy.append(provider)
        
        return healthy
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    async def health_check(self, provider: Provider) -> ProviderStatus:
        """Check provider health."""
        try:
            async with aiohttp.ClientSession() as session:
                headers = {"Authorization": f"Bearer {provider.api_key}"}
                
                async with session.get(
                    f"{provider.base_url}/models",
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        return ProviderStatus.HEALTHY
                    elif response.status < 500:
                        return ProviderStatus.DEGRADED
                    else:
                        return ProviderStatus.UNHEALTHY
                        
        except asyncio.TimeoutError:
            return ProviderStatus.DEGRADED
        except Exception as e:
            self.logger.error(f"Health check failed for {provider.name}: {e}")
            return ProviderStatus.UNHEALTHY
    
    async def update_provider_status(self):
        """Update status for all providers."""
        tasks = []
        
        for provider in self.providers.values():
            task = self.health_check(provider)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for provider, result in zip(self.providers.values(), results):
            if isinstance(result, ProviderStatus):
                provider.status = result
            else:
                provider.status = ProviderStatus.OFFLINE
                self.logger.error(f"Provider {provider.name} status update failed: {result}")
''',
                'requirements.txt': '''# AI API Liaison Dependencies

# Core Framework
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.5.0

# HTTP Client & Resilience
aiohttp>=3.9.0
httpx>=0.25.0
tenacity>=8.2.0

# AI Provider SDKs
openai>=1.3.0
anthropic>=0.7.0

# Cost & Analytics
tiktoken>=0.5.0
numpy>=1.24.0
pandas>=2.1.0

# Monitoring & Logging
structlog>=23.2.0

# Selection & ML
scikit-learn>=1.3.0
scipy>=1.11.0

# Configuration & Environment
python-dotenv>=1.0.0
pyyaml>=6.0.1
''',
                'tests/test_provider_manager.py': '''"""
Tests for Provider Manager
"""

import pytest
import asyncio
from unittest.mock import Mock, patch

from core.provider_manager import ProviderManager, ProviderStatus


class TestProviderManager:
    """Test cases for ProviderManager."""
    
    @pytest.fixture
    def provider_manager(self):
        """Create a ProviderManager instance."""
        return ProviderManager()
    
    def test_provider_initialization(self, provider_manager):
        """Test provider initialization."""
        assert len(provider_manager.providers) == 3
        assert "openai" in provider_manager.providers
        assert "anthropic" in provider_manager.providers
        assert "google" in provider_manager.providers
''',
                'config/providers.yaml': '''# AI Provider Configuration

providers:
  openai:
    name: "OpenAI"
    models:
      - "gpt-4"
      - "gpt-3.5-turbo"
    rate_limit: 3000
    cost_per_token: 0.03
    priority: 1
    
  anthropic:
    name: "Anthropic"
    models:
      - "claude-3-opus"
      - "claude-3-sonnet"
    rate_limit: 1000
    cost_per_token: 0.015
    priority: 2
''',
                '.env.example': '''# AI API Liaison Environment Configuration

# AI Provider API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Application Configuration
DEBUG=false
LOG_LEVEL=info
HOST=0.0.0.0
PORT=8000
'''
            }
            
            # Sample repository information with realistic data
            repositories = [
                {
                    'name': 'gracy',
                    'url': 'https://github.com/guilatrova/gracy',
                    'files_copied': [
                        'gracy/client.py',
                        'gracy/throttle.py',
                        'gracy/hooks.py'
                    ],
                    'purpose': 'Complete API client framework with resilience patterns',
                    'license': 'MIT'
                },
                {
                    'name': 'api-oss',
                    'url': 'https://github.com/zukijourney/api-oss',
                    'files_copied': [
                        'api/app/api/routes/route.py',
                        'api/app/api/constants.py',
                        'api/app/api/dependencies.py'
                    ],
                    'purpose': 'Core routing infrastructure and OpenAI compatibility',
                    'license': 'Apache-2.0'
                }
            ]
            
            # Project description for AI analysis
            project_description = """
            Create an AI API Liaison system that provides intelligent routing and management 
            across multiple AI providers (OpenAI, Anthropic, Google). The system should include:
            
            - Multi-provider support with health monitoring
            - Intelligent routing based on cost, performance, and availability
            - Resilience patterns (circuit breakers, retries, fallbacks)
            - Cost optimization and budget management
            - Comprehensive monitoring and analytics
            - OpenAI-compatible API interface
            """
            
            # Generate project with AI-integrated report
            print("📝 Generating project with AI-integrated comprehensive report...")
            project = await generator.generate_project(
                project_name="AIAPILiaison",
                output_dir=temp_dir,
                files=test_files,
                project_description=project_description,
                language="python",
                repositories=repositories,
                generate_report=True
            )
            
            print(f"✅ Project generated successfully!")
            print(f"   Name: {project.name}")
            print(f"   Path: {project.path}")
            print(f"   Files: {len(project.files)}")
            print(f"   Size: {project.size} bytes")
            
            if project.report_path:
                print(f"   AI Report: {project.report_path}")
                
                # Read and display part of the AI-integrated report
                with open(project.report_path, 'r') as f:
                    report_content = f.read()
                
                print("\n🤖 AI-Integrated Report Preview:")
                print("-" * 50)
                # Show first 2000 characters of the report
                print(report_content[:2000])
                if len(report_content) > 2000:
                    print("...")
                    print(f"\n[Report continues for {len(report_content) - 2000} more characters]")
                
                print(f"\n✅ Full AI-integrated report saved as README.md: {project.report_path}")
                
                # Verify the report contains AI analysis elements
                ai_elements = [
                    "AI-POWERED ANALYSIS",
                    "AI-ANALYZED FILE STRUCTURE", 
                    "AI-DRIVEN REPOSITORY INTEGRATION",
                    "COMPREHENSIVE AI ANALYSIS RESULTS",
                    "AI-OPTIMIZED IMPLEMENTATION PHASES",
                    "AI-DETERMINED DEVELOPMENT PRIORITIES"
                ]
                
                found_elements = [elem for elem in ai_elements if elem in report_content]
                print(f"\n🎯 AI Analysis Elements Found: {len(found_elements)}/{len(ai_elements)}")
                for element in found_elements:
                    print(f"   ✅ {element}")
                
                if len(found_elements) >= 4:
                    print("\n🎉 AI-INTEGRATED REPORTING SUCCESS!")
                    print("The system now generates comprehensive reports using:")
                    print("   🤖 AI file analysis with quality scoring")
                    print("   🔍 Repository discovery with relevance scoring")
                    print("   📊 Security and compliance metrics")
                    print("   🚀 Implementation phases based on AI priorities")
                    print("   ⭐ Development recommendations from AI analysis")
                    return True
                else:
                    print("\n⚠️ Some AI analysis elements missing from report")
                    return False
            else:
                print("\n❌ No report generated")
                return False
            
    except Exception as e:
        print(f"❌ AI-integrated reporting test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """Run the AI-integrated reporting system test."""
    
    print("🧪 AutoBot Assembly System - AI-Integrated Reporting Test")
    print("=" * 70)
    
    success = await test_ai_integrated_reporting()
    
    if success:
        print("\n🎉 AI-INTEGRATED REPORTING SYSTEM TEST PASSED!")
        print("\n🤖 New AI-Powered Features:")
        print("✅ Unified file scoring with MegaLinter, Semgrep, AST-grep")
        print("✅ AI-driven repository discovery with quality scoring")
        print("✅ Security and compliance metrics integration")
        print("✅ AI-determined file purposes and recommendations")
        print("✅ Implementation phases based on AI analysis")
        print("✅ Development priorities from composite scoring")
        print("✅ Comprehensive README.md report generation")
        print("\n🚀 The AutoBot Assembly System now generates AI-integrated reports!")
        print("📋 Reports include all existing AI analysis results and metrics!")
    else:
        print("\n❌ AI-integrated reporting system test failed.")
        print("🔧 Check the AI analysis integration and report generation.")


if __name__ == "__main__":
    asyncio.run(main())